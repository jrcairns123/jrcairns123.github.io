{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import csv\n",
    "import networkx as nx\n",
    "from networkx.algorithms.community.modularity_max import greedy_modularity_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(file):\n",
    "\n",
    "    df = pd.read_csv(file, header=None, index_col=0)\n",
    "    df_filtered = df[(df[7]==400) | (df[7]==420) | (df[7]==430) | (df[7]==440)].iloc[:,7:]\n",
    "    x = df_filtered[df_filtered.columns[1::3]].columns.union([22,37])\n",
    "    toStack = [df_filtered[x].iloc[:,:6],df_filtered[x].iloc[:,6:]]\n",
    "    \n",
    "    columnNames = [\"Top\",\"Jungle\",\"Middle\",\"Bot\",\"Support\",\"Win\"]\n",
    "    for i in toStack:\n",
    "        i.columns=columnNames\n",
    "\n",
    "    df = pd.concat(toStack).reset_index(drop=True)\n",
    "    df['Win'] = df['Win'].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_champ_counts(champ_counts, teams):\n",
    "    for a in teams:\n",
    "        champ_counts[a] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_champ_pair_counts (champ_pair_counts, teams):\n",
    "    for (a, b) in combinations (teams, 2):\n",
    "        champ_pair_counts[(a, b)] += 1\n",
    "        champ_pair_counts[(b, a)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_champ_pair_wins(champ_pair_wins, teams):\n",
    "    for (a, b) in combinations (teams, 2):\n",
    "        if teams[5] == 1:\n",
    "            champ_pair_wins[(a, b)] += 1\n",
    "            champ_pair_wins[(b, a)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rules(champ_pair_counts, champ_counts, conf_threshold, size):\n",
    "    rules = {}\n",
    "    lifts = {}\n",
    "    for (a, b) in champ_pair_counts:\n",
    "        conf_ab = champ_pair_counts[(a, b)] / champ_counts[a] * 100\n",
    "        conf_ba = champ_pair_counts[(a, b)] / champ_counts[b] * 100\n",
    "        lift_ab = (champ_pair_counts[(a, b)]/size) / (champ_counts[a]/size *champ_counts[b]/size)\n",
    "        if conf_ab >= conf_threshold:\n",
    "            rules[(a, b)] = conf_ab\n",
    "            rules[(b, a)] = conf_ba\n",
    "            if lift_ab > 1:\n",
    "                lifts[(a,b)] = lift_ab\n",
    "                lifts[(b,a)] = lift_ab\n",
    "    return rules, lifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_supports(champ_pair_counts, allTeams, sup_threshold):\n",
    "    supports = {}\n",
    "    for k,v in champ_pair_counts.items():\n",
    "        #toKey = tuple(sorted(list(k)))\n",
    "        supp_ab = v/len(allTeams)*100\n",
    "        if supp_ab >= sup_threshold:\n",
    "            supports[k] = supp_ab\n",
    "    return supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_rules(allTeams, withWins, sup_threshold, conf_threshold):\n",
    "    champ_pair_counts = defaultdict(int)\n",
    "    champ_counts = defaultdict(int)\n",
    "    champ_pair_wins = defaultdict(int)\n",
    "    size = len(allTeams)\n",
    "\n",
    "    for teams in allTeams:\n",
    "        update_champ_pair_counts(champ_pair_counts, teams)\n",
    "        update_champ_counts(champ_counts, teams)\n",
    "    \n",
    "    for teams in withWins:\n",
    "        update_champ_pair_wins(champ_pair_wins, teams)\n",
    "    \n",
    "    rules, lifts = filter_rules(champ_pair_counts, champ_counts, conf_threshold,size)\n",
    "    supports = filter_supports(champ_pair_counts, allTeams, sup_threshold)\n",
    "    \n",
    "    return supports, rules, lifts,champ_pair_counts, champ_pair_wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterGraph(z1,z4,z5, winRates):\n",
    "    champ_win_rates = dict(((key, z5[key]/z4[key]) for key in z4.keys()))\n",
    "    filtered_win_rates = dict(((k,v) for k,v in champ_win_rates.items() if v > winRates))\n",
    "    filtered_supps = dict(((k,v) for k,v in z1.items() if k in filtered_win_rates.keys()))\n",
    "    finalDict = {}\n",
    "    for k,v in filtered_supps.items():\n",
    "        toKey = tuple(sorted(list(k)))\n",
    "        if toKey not in finalDict:\n",
    "            finalDict[toKey]=v\n",
    "    return finalDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEdges(finalDict):\n",
    "    finalList = []\n",
    "    for item, values in finalDict.items():\n",
    "        finalList.append([item[0],item[1],values])\n",
    "    return finalList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNodes(finalDict, finalList):\n",
    "    nodesData = defaultdict(int)\n",
    "    for item, values in finalDict.items():\n",
    "        if (item[0] not in nodesData.keys()) or (item[1] not in nodesData.keys()):\n",
    "            nodesData[item[0]]\n",
    "            nodesData[item[1]]\n",
    "    \n",
    "    finalNodes = []\n",
    "    for item, values in nodesData.items():\n",
    "        finalNodes.append([item,values])\n",
    "     \n",
    "    G = nx.Graph()\n",
    "    for a in finalList:\n",
    "        G.add_edge(a[0],a[1],weight = a[2])\n",
    "    \n",
    "    communities= sorted(greedy_modularity_communities(G))\n",
    "    \n",
    "    for i in range(len(finalNodes)):\n",
    "        for j in range(len(communities)):\n",
    "            if finalNodes[i][0] in communities[j]:\n",
    "                if len(communities[j]) == 1:\n",
    "                    finalNodes[i][1] = 0\n",
    "                else:    \n",
    "                    finalNodes[i][1] = j+1\n",
    "    return finalNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runAlgos(file, winRate):\n",
    "    x = processData(file)\n",
    "    x_1 = x.drop(columns=['Win']).to_numpy()\n",
    "    x_2 = x.to_numpy() \n",
    "    \n",
    "    z1, z2, z3, z4, z5 = mine_rules(x_1,x_2,0.1,5)\n",
    "    \n",
    "    finalDict = filterGraph(z1,z4,z5,winRate) \n",
    "    finalEdges = createEdges(finalDict)\n",
    "    finalNodes = createNodes(finalDict, finalEdges)\n",
    "    \n",
    "    return finalNodes, finalEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/matchdata_eun1.csv'\n",
    "finalNodes, finalEdges = runAlgos(file, 0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Diana', 7],\n",
       " ['Viego', 10],\n",
       " ['Seraphine', 7],\n",
       " ['Graves', 0],\n",
       " ['Malphite', 23],\n",
       " ['Lux', 16],\n",
       " ['Soraka', 0],\n",
       " ['Vex', 30],\n",
       " ['Vayne', 15],\n",
       " ['Nocturne', 2]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalNodes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Diana', 'Viego', 0.114944478847671],\n",
       " ['Diana', 'Seraphine', 0.11367203074234622],\n",
       " ['Graves', 'Malphite', 0.20995393737858725],\n",
       " ['Lux', 'Soraka', 0.12639651179559394],\n",
       " ['Soraka', 'Vex', 0.17941518285079272],\n",
       " ['Soraka', 'Vayne', 0.28502837559274874],\n",
       " ['Nocturne', 'Tristana', 0.18832231958806614],\n",
       " ['Maokai', 'MissFortune', 0.11706522568987894],\n",
       " ['Jhin', 'Xerath', 0.38979326959782157],\n",
       " ['Lux', 'Xerath', 0.17178049421884412]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalEdges[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unhash when you want to writer the csv\n",
    "## be sure to create a unique name for the files\n",
    "## e.g. edges_eun1.csv and nodes_eun1.csv\n",
    "\n",
    "#headers = ['source', 'target', 'value']\n",
    "#with open(\"edges.csv\", \"w\", newline=\"\") as e:\n",
    "#    writer = csv.writer(e)\n",
    "#    writer.writerow(headers)\n",
    "#    writer.writerows(finalEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#headers = ['id','group']\n",
    "#with open('nodes.csv','w',newline='') as n:\n",
    "#    writer = csv.writer(n)\n",
    "#    writer.writerow(headers)\n",
    "#    writer.writerows(finalNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
